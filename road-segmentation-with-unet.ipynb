{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":1634186,"sourceType":"datasetVersion","datasetId":966140}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install tf-explain","metadata":{"execution":{"iopub.status.busy":"2024-11-18T13:59:36.216206Z","iopub.execute_input":"2024-11-18T13:59:36.216882Z","iopub.status.idle":"2024-11-18T13:59:49.284499Z","shell.execute_reply.started":"2024-11-18T13:59:36.21682Z","shell.execute_reply":"2024-11-18T13:59:49.283468Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Common\nimport os \nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom IPython.display import clear_output as cls\n\n# Data \nfrom tqdm import tqdm\nimport tensorflow.data as tfd\n\n# Data Visualization\nimport matplotlib.pyplot as plt\n\n# Model Building\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import callbacks\nfrom tensorflow.keras import optimizers\nfrom tensorflow.keras import metrics\nfrom tensorflow.keras.optimizers.schedules import ExponentialDecay\n\n# Model visualization\nfrom tensorflow.keras.utils import plot_model\nfrom tf_explain.core.grad_cam import GradCAM\n\n# Extra\nfrom typing import List, Tuple, Union","metadata":{"execution":{"iopub.status.busy":"2024-11-18T14:00:14.882912Z","iopub.execute_input":"2024-11-18T14:00:14.883297Z","iopub.status.idle":"2024-11-18T14:00:27.437304Z","shell.execute_reply.started":"2024-11-18T14:00:14.883263Z","shell.execute_reply":"2024-11-18T14:00:27.436356Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Image and Mask Dimensions\nIMAGE_HEIGHT = 256\nIMAGE_WIDTH = 256\nN_IMAGE_CHANNELS = 3\nN_MASK_CHANNELS = 1\n\n# Image and Mask Size\nIMAGE_SIZE = (IMAGE_WIDTH, IMAGE_HEIGHT, N_IMAGE_CHANNELS)\nMASK_SIZE = (IMAGE_WIDTH, IMAGE_HEIGHT, N_MASK_CHANNELS)\n\n# Zoom factor: a value less than 1.0 zooms out, greater than 1.0 zooms in\nZOOM_FACTOR = 4.5\n    \n# Batch Size and Learning Rate\nBATCH_SIZE = 32\nBASE_LR = 1e-3\n\n# Model Name\nMODEL_NAME = 'SIH_T2'\n\n# Model Training\nEPOCHS = 100\n\n# Data Paths\nROOT_DIR = 'ADD YOUR PATG'\nMETADATA_CSV_PATH = 'ADD YOUR META DATA PATAH'\n\n# Model Architecture\nFILTERS = 32","metadata":{"execution":{"iopub.status.busy":"2024-11-18T14:08:50.952344Z","iopub.execute_input":"2024-11-18T14:08:50.953185Z","iopub.status.idle":"2024-11-18T14:08:50.959017Z","shell.execute_reply.started":"2024-11-18T14:08:50.953148Z","shell.execute_reply":"2024-11-18T14:08:50.958114Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Random Seed\nSEED = 42\n\nnp.random.seed(SEED)\ntf.random.set_seed(SEED)","metadata":{"execution":{"iopub.status.busy":"2024-11-18T14:08:51.311427Z","iopub.execute_input":"2024-11-18T14:08:51.311768Z","iopub.status.idle":"2024-11-18T14:08:51.3184Z","shell.execute_reply.started":"2024-11-18T14:08:51.311735Z","shell.execute_reply":"2024-11-18T14:08:51.317398Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def load_image_and_mask(image_path: str, mask_path: str) -> Tuple[tf.Tensor, tf.Tensor]:\n    \n    '''\n    This function takes the file paths of an image and its corresponding mask as input. It first reads the images, then decodes them into tensors, \n    and resizes them to a standard size. After that, the image and mask tensors are normalized by clipping the pixel values between 0 and 1. \n    Finally, the function converts the image and mask tensors to the float32 data type and returns them as a tuple.\n    \n    Arguments : \n        image_path : The path to the image to be loaded. \n        mask_path  : The path to the mask to be loaded.\n    \n    Returns :\n        image : This is the loaded and the processed image. \n        mask  : This is the loaded and the processed mask.\n    \n    '''\n    \n    # Read the images\n    image = tf.io.read_file(filename = image_path)\n    mask  = tf.io.read_file(filename = mask_path)\n    \n    # Decode the images\n    image = tf.image.decode_jpeg(contents = image, channels = N_IMAGE_CHANNELS)\n    mask  = tf.image.decode_jpeg(contents = mask,  channels = N_MASK_CHANNELS)\n    \n    # Convert the image to a Tensor\n    image = tf.image.convert_image_dtype(image = image, dtype = tf.float32)\n    mask  = tf.image.convert_image_dtype(image = mask, dtype = tf.float32)\n    \n    # Crop the image and mask to zoom in\n    crop_height = int(IMAGE_HEIGHT / ZOOM_FACTOR)\n    crop_width = int(IMAGE_WIDTH / ZOOM_FACTOR)\n    \n    image = tf.image.central_crop(image, central_fraction=1/ZOOM_FACTOR)\n    mask = tf.image.central_crop(mask, central_fraction=1/ZOOM_FACTOR)\n    \n    # Resize the cropped images back to the original dimensions\n    image = tf.image.resize(image, size=(IMAGE_HEIGHT, IMAGE_WIDTH))\n    mask = tf.image.resize(mask, size=(IMAGE_HEIGHT, IMAGE_WIDTH))\n\n    # Normalize the image\n    image = tf.clip_by_value(image, clip_value_min = 0.0, clip_value_max = 1.0)\n    mask  = tf.clip_by_value(mask, clip_value_min = 0.0, clip_value_max = 1.0)\n    \n    # Final conversion\n    image = tf.cast(image, dtype = tf.float32)\n    mask  = tf.cast(mask,  dtype = tf.float32)\n    \n    return image, mask","metadata":{"execution":{"iopub.status.busy":"2024-11-18T14:08:51.949144Z","iopub.execute_input":"2024-11-18T14:08:51.949521Z","iopub.status.idle":"2024-11-18T14:08:51.959805Z","shell.execute_reply.started":"2024-11-18T14:08:51.949484Z","shell.execute_reply":"2024-11-18T14:08:51.958814Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load CSV File\nmetadata = pd.read_csv(METADATA_CSV_PATH)\n\n# Quick look\nmetadata.head()","metadata":{"execution":{"iopub.status.busy":"2024-11-18T14:08:52.262365Z","iopub.execute_input":"2024-11-18T14:08:52.262758Z","iopub.status.idle":"2024-11-18T14:08:52.289727Z","shell.execute_reply.started":"2024-11-18T14:08:52.262721Z","shell.execute_reply":"2024-11-18T14:08:52.288834Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Seperate Training and Testing metadata\ntest_metadata = metadata[metadata['split']==\"test\"]\nmetadata = metadata[metadata['split']==\"train\"]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T14:08:52.872022Z","iopub.execute_input":"2024-11-18T14:08:52.872388Z","iopub.status.idle":"2024-11-18T14:08:52.882345Z","shell.execute_reply.started":"2024-11-18T14:08:52.872352Z","shell.execute_reply":"2024-11-18T14:08:52.881469Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Add root path to image file names\nmetadata['image'] = [os.path.join(ROOT_DIR,str(filename)) for filename in metadata['sat_image_path']]\n\n# Add mask path to image file names\nmetadata['mask']  = [os.path.join(ROOT_DIR,str(filename)) for filename in metadata['mask_path']]","metadata":{"execution":{"iopub.status.busy":"2024-11-18T14:08:53.031165Z","iopub.execute_input":"2024-11-18T14:08:53.0316Z","iopub.status.idle":"2024-11-18T14:08:53.066841Z","shell.execute_reply.started":"2024-11-18T14:08:53.031564Z","shell.execute_reply":"2024-11-18T14:08:53.065932Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"image_id = 478\nsample_image, sample_mask = load_image_and_mask(metadata['image'][image_id], metadata['mask'][image_id])\n\nplt.figure(figsize=(10, 8))\nplt.subplot(1,2,1)\nplt.imshow(sample_image)\nplt.axis('off')\n\nplt.subplot(1,2,2)\nplt.imshow(sample_mask, cmap='gray')\nplt.axis('off')\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T14:09:15.563358Z","iopub.execute_input":"2024-11-18T14:09:15.563752Z","iopub.status.idle":"2024-11-18T14:09:15.838976Z","shell.execute_reply.started":"2024-11-18T14:09:15.563714Z","shell.execute_reply":"2024-11-18T14:09:15.838013Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Quick Check\nmetadata.head()","metadata":{"execution":{"iopub.status.busy":"2024-11-18T14:09:16.917167Z","iopub.execute_input":"2024-11-18T14:09:16.917807Z","iopub.status.idle":"2024-11-18T14:09:16.92977Z","shell.execute_reply.started":"2024-11-18T14:09:16.917765Z","shell.execute_reply":"2024-11-18T14:09:16.928836Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def load_dataset(\n    image_paths: list, mask_paths: list, split_ratio: float=0.2, \n    batch_size: int=BATCH_SIZE, shuffle: bool=True, \n    buffer_size: int=1000, n_repeat: int=1\n) -> Union[Tuple[tfd.Dataset, tfd.Dataset], tfd.Dataset]:\n    '''\n    This function loads the image and mask data from the provided file paths and creates a TensorFlow dataset. The function\n    first creates space to store the image and mask data in numpy arrays. It then iterates over each image and mask pair, \n    loading them using the load_image_and_mask function and storing them in the numpy arrays.\n    \n    The function then creates a TensorFlow dataset using the numpy arrays. If shuffle is True, it shuffles the dataset\n    with a buffer size of buffer_size. If split_ratio is not None, it splits the dataset into two parts with sizes determined\n    by the split_ratio, and converts them into batches of size batch_size with drop_remainder=True. The two resulting datasets\n    are returned as a tuple.\n\n    If split_ratio is None, the entire dataset is converted into batches of size batch_size with drop_remainder=True, \n    and the resulting dataset is returned.\n    \n    Args:\n        image_paths: A list of strings, containing the file paths of the input images.\n        \n        mask_paths: A list of strings, containing the file paths of the corresponding mask images.\n        \n        split_ratio: A float value between 0 and 1, representing the ratio of data to be used for validation. \n                    If split_ratio is set to None, then no data will be split for validation.\n                    \n        batch_size: An integer, representing the batch size for the input data.\n        \n        shuffle: A boolean value indicating whether the data should be shuffled or not.\n        \n        buffer_size: An integer, representing the buffer size for shuffling the data.\n        \n        n_repeat: An integer, representing the total number of repetations of the data.\n    \n    Returns:\n        If split_ratio is not None, then the function returns a tuple of two Tensorflow datasets. \n        The first dataset contains the training data and the second dataset contains the validation data.\n        \n        If split_ratio is None, then the function returns a single Tensorflow dataset containing the \n        input data batched and pre-fetched for training.\n    \n    '''\n    \n    # Create space for storing the data.\n    images = np.empty(shape=(len(image_paths), *IMAGE_SIZE), dtype=np.float32)\n    masks  = np.empty(shape=(len(mask_paths), *MASK_SIZE),  dtype=np.float32)\n    \n    # Iterate over the data.\n    index = 0\n    for image_path, mask_path in tqdm(zip(image_paths, mask_paths), desc='Loading'):\n        \n        # Load the image and the mask.\n        image, mask = load_image_and_mask(image_path = image_path, mask_path = mask_path)\n        \n        # Store the image and the mask.\n        images[index] = image\n        masks[index]  = mask\n        \n        # Increment the index.\n        index += 1\n    \n    # Create a Tensorflow data.\n    data_set = tfd.Dataset.from_tensor_slices((images, masks)).repeat(n_repeat)\n    \n    # Shuffle the data set.\n    if shuffle:\n        data_set = data_set.shuffle(buffer_size)\n    \n    # Split the data \n    if split_ratio is not None:\n        \n        # Calculate new data sizes after splitting.\n        keep_ratio = 1-split_ratio\n        data_1_len = int((keep_ratio) * len(images))\n        data_2_len = int(split_ratio * len(images))\n        \n        # Divide the data into 2 parts.\n        data_1 = data_set.take(data_1_len)\n        data_2 = data_set.skip(data_1_len).take(data_2_len)\n        \n        # Convert data into batches.\n        data_1 = data_1.batch(batch_size, drop_remainder=True).prefetch(tfd.AUTOTUNE)\n        data_2 = data_2.batch(batch_size, drop_remainder=True).prefetch(tfd.AUTOTUNE)\n        \n        # Return the data \n        return data_1, data_2\n    \n    else:\n        \n        # Convert data into batches\n        data_set = data_set.batch(batch_size, drop_remainder=True).prefetch(tfd.AUTOTUNE)\n        \n        # Return the data\n        return data_set","metadata":{"execution":{"iopub.status.busy":"2024-11-18T14:09:17.49616Z","iopub.execute_input":"2024-11-18T14:09:17.496564Z","iopub.status.idle":"2024-11-18T14:09:17.510835Z","shell.execute_reply.started":"2024-11-18T14:09:17.496524Z","shell.execute_reply":"2024-11-18T14:09:17.509783Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Training and Testing Data\nfull_train_ds, test_ds = load_dataset(\n    image_paths = metadata['image'],\n    mask_paths = metadata['mask'],\n    split_ratio = 0.1,\n    shuffle = True,\n    n_repeat=3,\n)","metadata":{"execution":{"iopub.status.busy":"2024-11-18T14:09:20.235114Z","iopub.execute_input":"2024-11-18T14:09:20.235938Z","iopub.status.idle":"2024-11-18T14:14:20.063689Z","shell.execute_reply.started":"2024-11-18T14:09:20.235896Z","shell.execute_reply":"2024-11-18T14:14:20.062833Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"*\"*100)\nprint(f\"{' '*30}Training Data Size : {full_train_ds.cardinality().numpy() * BATCH_SIZE}\")\nprint(f\"{' '*30}Testing Data Size  : {test_ds.cardinality().numpy() * BATCH_SIZE}\")\nprint(\"*\"*100)","metadata":{"execution":{"iopub.status.busy":"2024-11-18T14:14:25.066984Z","iopub.execute_input":"2024-11-18T14:14:25.067368Z","iopub.status.idle":"2024-11-18T14:14:25.074061Z","shell.execute_reply.started":"2024-11-18T14:14:25.067304Z","shell.execute_reply":"2024-11-18T14:14:25.07311Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Training Data size\nfull_train_size = full_train_ds.cardinality().numpy()\n\n# Split Ratio\ntrain_val_split = 0.1\nvalid_size = int(full_train_size * train_val_split)\ntrain_size = full_train_size - valid_size\n\n# Split Data \ntrain_ds = full_train_ds.take(train_size)\nvalid_ds = full_train_ds.skip(train_size).take(valid_size)","metadata":{"execution":{"iopub.status.busy":"2024-11-18T14:14:27.043831Z","iopub.execute_input":"2024-11-18T14:14:27.044215Z","iopub.status.idle":"2024-11-18T14:14:27.055683Z","shell.execute_reply.started":"2024-11-18T14:14:27.044178Z","shell.execute_reply":"2024-11-18T14:14:27.054717Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"*\"*100)\nprint(f\"{' '*30}Training Data Size   : {train_ds.cardinality().numpy() * BATCH_SIZE}\")\nprint(f\"{' '*30}Validation Data Size : {valid_ds.cardinality().numpy() * BATCH_SIZE}\")\nprint(f\"{' '*30}Testing Data Size    : {test_ds.cardinality().numpy() * BATCH_SIZE}\")\nprint(\"*\"*100)","metadata":{"execution":{"iopub.status.busy":"2024-11-18T14:14:27.969915Z","iopub.execute_input":"2024-11-18T14:14:27.971073Z","iopub.status.idle":"2024-11-18T14:14:27.977465Z","shell.execute_reply.started":"2024-11-18T14:14:27.971027Z","shell.execute_reply":"2024-11-18T14:14:27.976551Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Data Visualization**","metadata":{}},{"cell_type":"code","source":"def show_images_and_masks(data : tfd.Dataset, n_images: int=10, FIGSIZE: tuple=(25, 5), model: tf.keras.Model=None):\n    \n    # Configuration\n    if model is None:\n        n_cols = 3\n    else:\n        n_cols = 5\n    \n    # Collect the data\n    images, masks = next(iter(data))\n    \n    # Iterate over the data\n    for n in range(n_images):\n        \n        # Plotting configuration\n        plt.figure(figsize=FIGSIZE)\n        \n        # Plot the image\n        plt.subplot(1, n_cols, 1)\n        plt.title(\"Original Image\")\n        plt.imshow(images[n])\n        plt.axis('off')\n        \n        # Plot the Mask\n        plt.subplot(1, n_cols, 2)\n        plt.title(\"Original Mask\")\n        plt.imshow(masks[n], cmap='gray')\n        plt.axis('off')\n        \n        # Plot image and mask overlay\n        plt.subplot(1, n_cols, 3)\n        plt.title('Image and Mask overlay')\n        plt.imshow(masks[n], alpha=0.8, cmap='binary_r')\n        plt.imshow(images[n], alpha=0.5)\n        plt.axis('off')\n        \n        # Model predictions\n        if model is not None:\n            pred_mask = model.predict(tf.expand_dims(images[n], axis=0))[0]\n            pred_mask = pred_mask>=0.5\n            plt.subplot(1, n_cols, 4)\n            plt.title('Predicted Mask')\n            plt.imshow(pred_mask, cmap='gray')\n            plt.axis('off')\n            \n            plt.subplot(1, n_cols, 5)\n            plt.title('Predicted Mask Overlay')\n            plt.imshow(pred_mask, alpha=0.8, cmap='binary_r')\n            plt.imshow(images[n], alpha=0.5)\n            plt.axis('off')\n    \n        # Show final plot\n        plt.show()\n\nshow_images_and_masks(data=train_ds)","metadata":{"execution":{"iopub.status.busy":"2024-11-18T14:14:30.971878Z","iopub.execute_input":"2024-11-18T14:14:30.972504Z","iopub.status.idle":"2024-11-18T14:14:41.014464Z","shell.execute_reply.started":"2024-11-18T14:14:30.972464Z","shell.execute_reply":"2024-11-18T14:14:41.013589Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class EncoderBlock(layers.Layer):\n    \n    def __init__(self, filters: int, max_pool: bool=True, rate=0.2, **kwargs) -> None:\n        super().__init__(**kwargs)\n        \n        # Params\n        self.rate = rate\n        self.filters = filters\n        self.max_pool = max_pool\n        \n        # Layers : Initialize the model layers that will be later called\n        self.max_pooling = layers.MaxPool2D(pool_size=(2,2), strides=(2,2))\n        self.conv1 = layers.Conv2D(\n            filters=filters,\n            kernel_size=3,\n            strides=1,\n            padding='same',\n            activation='relu',\n            kernel_initializer='he_normal'\n        )\n        self.conv2 = layers.Conv2D(\n            filters=filters,\n            kernel_size=3,\n            strides=1,\n            padding='same',\n            activation='relu',\n            kernel_initializer='he_normal'\n        )\n        self.drop = layers.Dropout(rate)\n        self.bn = layers.BatchNormalization()\n        \n    def call(self, X, **kwargs):\n        \n        X = self.bn(X)\n        X = self.conv1(X)\n        X = self.drop(X)\n        X = self.conv2(X)\n        \n        # Apply Max Pooling if required\n        if self.max_pool:\n            y = self.max_pooling(X)\n            return y, X\n        else:\n            return X\n    \n    def get_config(self):\n        config = super().get_config()\n        config.update({\n            'filters': self.filters,\n            'max_pool': self.max_pool,\n            'rate': self.rate\n        })\n        return config\n\n    def __repr__(self):\n        return f\"{self.__class__.__name__}(F={self.filters}, Pooling={self.max_pool})\"","metadata":{"execution":{"iopub.status.busy":"2024-11-18T14:15:03.031086Z","iopub.execute_input":"2024-11-18T14:15:03.032031Z","iopub.status.idle":"2024-11-18T14:15:03.042821Z","shell.execute_reply.started":"2024-11-18T14:15:03.031987Z","shell.execute_reply":"2024-11-18T14:15:03.041853Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class DecoderBlock(layers.Layer):\n    \n    def __init__(self, filters: int, rate: float = 0.2, **kwargs):\n        super().__init__(**kwargs)\n        \n        self.filters = filters\n        self.rate = rate\n        \n        # Initialize the model layers\n        self.convT = layers.Conv2DTranspose(\n            filters = filters,\n            kernel_size = 3,\n            strides = 2,\n            padding = 'same',\n            activation = 'relu',\n            kernel_initializer = 'he_normal'\n        )\n        self.bn = layers.BatchNormalization()\n        self.net = EncoderBlock(filters = filters, rate = rate, max_pool = False)\n        \n    def call(self, inputs, **kwargs):\n        \n        # Get both the inputs\n        X, skip_X = inputs\n        \n        # Up-sample the skip connection\n        X = self.bn(X)\n        X = self.convT(X)\n        \n        # Concatenate both inputs\n        X = layers.Concatenate(axis=-1)([X, skip_X])\n        X = self.net(X)\n        \n        return X\n\n    def get_config(self):\n        config = super().get_config()\n        config.update({\n            'filters': self.filters,\n            'rate': self.rate,\n        })\n        return config\n\n    def __repr__(self):\n        return f\"{self.__class__.__name__}(F={self.filters}, rate={self.rate})\"\n","metadata":{"execution":{"iopub.status.busy":"2024-11-18T14:15:03.356606Z","iopub.execute_input":"2024-11-18T14:15:03.356975Z","iopub.status.idle":"2024-11-18T14:15:03.366442Z","shell.execute_reply.started":"2024-11-18T14:15:03.356939Z","shell.execute_reply":"2024-11-18T14:15:03.36555Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Input Layer\ninput_layer = layers.Input(shape=(IMAGE_SIZE), name=\"InputLayer\")\n\n# The encoder network\npool1, encoder1 = EncoderBlock(FILTERS,   max_pool=True, rate=0.1, name=\"EncoderLayer1\")(input_layer)\npool2, encoder2 = EncoderBlock(FILTERS*2, max_pool=True, rate=0.1, name=\"EncoderLayer2\")(pool1)\npool3, encoder3 = EncoderBlock(FILTERS*4, max_pool=True, rate=0.2, name=\"EncoderLayer3\")(pool2)\npool4, encoder4 = EncoderBlock(FILTERS*8, max_pool=True, rate=0.2, name=\"EncoderLayer4\")(pool3)\n\n# The encoder encoding\nencoding = EncoderBlock(FILTERS*16, max_pool=False, rate=0.3, name=\"EncodingSpace\")(pool4)\n\n# The decoder network\ndecoder4 = DecoderBlock(FILTERS*8, rate=0.2, name=\"DecoderLayer1\")([encoding, encoder4])\ndecoder3 = DecoderBlock(FILTERS*4, rate=0.2, name=\"DecoderLayer2\")([decoder4, encoder3])\ndecoder2 = DecoderBlock(FILTERS*2, rate=0.1, name=\"DecoderLayer3\")([decoder3, encoder2])\ndecoder1 = DecoderBlock(FILTERS,  rate=0.1, name=\"DecoderLayer4\")([decoder2, encoder1])\n        \n# Final output layer.\nfinal_conv = layers.Conv2D(\n    filters = 1, \n    kernel_size = 1, \n    strides=1, \n    padding='same', \n    activation='sigmoid', \n    name=\"OutputMap\"\n)(decoder1)\n\n# Unet Model\nunet_model = keras.Model(\n    inputs = input_layer,\n    outputs = final_conv,\n    name = \"UNetModel\"\n)","metadata":{"execution":{"iopub.status.busy":"2024-11-18T14:15:04.238029Z","iopub.execute_input":"2024-11-18T14:15:04.238737Z","iopub.status.idle":"2024-11-18T14:15:05.469741Z","shell.execute_reply.started":"2024-11-18T14:15:04.238695Z","shell.execute_reply":"2024-11-18T14:15:05.468761Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Model Summary\nunet_model.summary()","metadata":{"execution":{"iopub.status.busy":"2024-11-18T14:15:05.471193Z","iopub.execute_input":"2024-11-18T14:15:05.471523Z","iopub.status.idle":"2024-11-18T14:15:05.507131Z","shell.execute_reply.started":"2024-11-18T14:15:05.47149Z","shell.execute_reply":"2024-11-18T14:15:05.506255Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"tf.keras.utils.plot_model(model = unet_model, to_file = \"UnetModel-SIH-ZoomedData.png\", dpi = 96, show_shapes=True)","metadata":{"execution":{"iopub.status.busy":"2024-11-18T14:15:08.855049Z","iopub.execute_input":"2024-11-18T14:15:08.855433Z","iopub.status.idle":"2024-11-18T14:15:09.299906Z","shell.execute_reply.started":"2024-11-18T14:15:08.855397Z","shell.execute_reply":"2024-11-18T14:15:09.298969Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **UNet - Model Training**\n---\n","metadata":{}},{"cell_type":"code","source":"# Exponential learning rate decay\n# initial_learning_rate = BASE_LR\n# decay_steps = 500\n# decay_rate = 0.96\n\n# lr_schedule = ExponentialDecay(\n#     initial_learning_rate,\n#     decay_steps,\n#     decay_rate,\n#     staircase=True\n# )\n\noptimizer = optimizers.Adam(learning_rate=BASE_LR)\n\n# Compile Model\nunet_model.compile(\n    loss = 'binary_crossentropy',\n    optimizer = optimizer,\n)","metadata":{"execution":{"iopub.status.busy":"2024-11-18T14:15:19.371569Z","iopub.execute_input":"2024-11-18T14:15:19.37243Z","iopub.status.idle":"2024-11-18T14:15:19.38434Z","shell.execute_reply.started":"2024-11-18T14:15:19.372383Z","shell.execute_reply":"2024-11-18T14:15:19.383534Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Model Training\nunet_model_history = unet_model.fit(\n    train_ds,\n    epochs = EPOCHS,\n    batch_size = BATCH_SIZE,\n    validation_data = valid_ds,\n)","metadata":{"execution":{"iopub.status.busy":"2024-11-18T14:15:31.08896Z","iopub.execute_input":"2024-11-18T14:15:31.089354Z","iopub.status.idle":"2024-11-18T14:17:17.285804Z","shell.execute_reply.started":"2024-11-18T14:15:31.089303Z","shell.execute_reply":"2024-11-18T14:17:17.284924Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"show_images_and_masks(data=train_ds, model=unet_model)","metadata":{"execution":{"iopub.status.busy":"2024-11-18T14:17:17.293365Z","iopub.execute_input":"2024-11-18T14:17:17.293743Z","iopub.status.idle":"2024-11-18T14:17:26.436641Z","shell.execute_reply.started":"2024-11-18T14:17:17.293693Z","shell.execute_reply":"2024-11-18T14:17:26.435825Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"show_images_and_masks(data=test_ds, model=unet_model)","metadata":{"execution":{"iopub.status.busy":"2024-11-18T14:17:26.438501Z","iopub.execute_input":"2024-11-18T14:17:26.438809Z","iopub.status.idle":"2024-11-18T14:17:33.972177Z","shell.execute_reply.started":"2024-11-18T14:17:26.438777Z","shell.execute_reply":"2024-11-18T14:17:33.971221Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"show_images_and_masks(data=test_ds, model=unet_model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T14:17:33.973239Z","iopub.execute_input":"2024-11-18T14:17:33.973553Z","iopub.status.idle":"2024-11-18T14:17:41.651062Z","shell.execute_reply.started":"2024-11-18T14:17:33.97352Z","shell.execute_reply":"2024-11-18T14:17:41.650154Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Save in Keras Format\nunet_model.save(MODEL_NAME + \"-SIH-ZoomedData.keras\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T02:37:50.522275Z","iopub.execute_input":"2024-11-18T02:37:50.522956Z","iopub.status.idle":"2024-11-18T02:37:51.070286Z","shell.execute_reply.started":"2024-11-18T02:37:50.522911Z","shell.execute_reply":"2024-11-18T02:37:51.069459Z"}},"outputs":[],"execution_count":null}]}